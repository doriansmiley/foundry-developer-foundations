import { Function, OntologyEditFunction, Edits, Integer, Double, Query, LocalDate, FunctionsMap, Timestamp } from "@foundry/functions-api";
import { Objects, MachineExecutions, Communications } from "@foundry/ontology-api";
import { Uuid } from "@foundry/functions-utils";
import { GPT_4o, Gemini_2_0_Flash } from '@foundry/models-api/language-models';
import { ExternalSystems } from "@foundry/functions-api";
import { FoundryApis, Slack, OpenAICodeStrapEng, RangrApis } from "@foundry/external-systems/sources";
import { Trace } from 'foundry-tracing-foundations/src';

import { Context, EvaluatorResult, MachineEvent, Solutions, StateConfig, Workflow, engineV1 as engine } from "./reasoning";
import { SupportedEngines, xReasonFactory } from "./reasoning/factory";
import { Text2Action } from ".";
import { uuidv4 } from "./utils";

interface SalesForgeTaskListResponse {
    status: Integer;
    message: string;
    executionId: string;
    taskList?: string;
    error?: string;
}

export type Role = {
    title: string,
    rate: number,
    rateType: 'hourly' | 'daily' | 'monthly' | 'yearly',
    quantity: number,
}
// used when parsing response from LLM
export type RfpResponse = {
    rawText: string;
    machineExecutionId: string;
    rateCard: Role[],
    cost: number,
    startDate: Date,
    terms: string;
}

interface RfpResponseReceipt {
    status: Integer;
    message: string;
    machineExecutionId: string;
    error?: string;
    reciept?: {
        id: string,
        timestamp: Timestamp,
    };
}

export class SalesForge {
    private text2ActionInstance: Text2Action;

    constructor() {
        this.text2ActionInstance = new Text2Action();
    }

    @Query({ apiName: 'askBennie' })
    @ExternalSystems({ sources: [FoundryApis, Slack, OpenAICodeStrapEng, RangrApis] })
    @Trace({
        resource: {
            service_name: 'bennie',
            service_instance_id: 'production',
            telemetry_sdk_name: 'xreason-functions',
            telemetry_sdk_version: '7.0.2',
            host_hostname: 'codestrap.usw-3.palantirfoundry.com',
            host_architecture: 'prod',
        },
        operationName: 'askBennie',
        kind: 'Server',
        samplingDecision: 'RECORD_AND_SAMPLE',
        samplingRate: 1.0,
        attributes: { endpoint: '/api/v2/ontologies/ontology-c0c8a326-cd0a-4f69-a575-b0399c04b74d/queries/askBennie/execute' }
    })
    public async askBennie(query: string, userId: string, threadId?:string): Promise<string> {
        // if threadId is defined look it up, else create a new thread in the ontology using fetch
        // create a new threadId in the ontology threads object if one isn't supplied or not found
        // call createSalesTasksFunction with the full thread history
        const { status, taskList, executionId } = await this.createSalesTasksFunction(query, userId, threadId);
        // if we get a bad response skip calling execute task list
        if (status !== 200 || !taskList) {
            return `You are missing required infromation: ${taskList}. Please fix your shit and resend.`
        }
        // execute the task list
        const results = await this.text2ActionInstance.executeTaskList(taskList, true, executionId, undefined, SupportedEngines.SALES)
        // construct the response
        // persist the constructed response to the the threads object
        // return the constructed response
        return results;
    }

    @Query({ apiName: "createSalesTasksFunction" })
    @ExternalSystems({ sources: [FoundryApis, RangrApis] })
    @Trace({
        resource: {
            service_name: 'bennie',
            service_instance_id: 'production',
            telemetry_sdk_name: 'xreason-functions',
            telemetry_sdk_version: '7.0.2',
            host_hostname: 'codestrap.usw-3.palantirfoundry.com',
            host_architecture: 'prod',
        },
        operationName: 'createSalesTasksFunction',
        kind: 'Server',
        samplingDecision: 'RECORD_AND_SAMPLE',
        samplingRate: 1.0,
        attributes: { endpoint: '/api/v2/ontologies/ontology-c0c8a326-cd0a-4f69-a575-b0399c04b74d/queries/createSalesTasksTasksFunction/execute' }
    })
    public async createSalesTasksFunction(query: string, userId: string, threadId?: string): Promise<SalesForgeTaskListResponse> {
        console.log('createSalesTasksTasksFunction called')
        // if no threadId create one
        // call the solver to get back the task list. 
        const taskList = await this.text2ActionInstance.createCommunicationsTasksFunction(query, userId, SupportedEngines.SALES)
        // If incomplete information is provided the solver will return Missing Infromation
        // If the request is unsupported the solver will return Usupported Questions
        // If it's a complete supported query the solver will return a well formatted task list that we can use to execute
        return {
            status: 200,
            message: 'Task list created',
            // we match the threadID and threadId and executionId so we can associate conversations between agents and machine executions
            executionId: threadId || uuidv4(),
            taskList,
        };
    }

    /**
     * A dedicated webhook callback for RFP submissions
     * Extract parameters from query param using an LLM. 
     * The client is expected to send the machine exection ID (which is the same as the orignal threadID) back in it's responses. 
     * We will have passed this ID to exteranl agents as part of createSalesTasks invocation above
     * If no machine exection ID is found throw ERROR
     * Use an LLM to extract the required parameters for an RFP from the provided query param such as:
        * Volume of staffing (we use Tech Leads, Engineers, and Engagement Directors)
        * Rate Card / how much itâ€™s going to cost. Monthly for long term, one time for short term where short term is < 2 months
        * Available Start Date
     * if any required parameters are missing return a a textual response stating what is missing along with a machine execution ID
     * Once all required parameters are retireved execute the request
     */
    @Query({ apiName: "submitRfpResponse" })
    @ExternalSystems({ sources: [FoundryApis, RangrApis] })
    @Trace({
        resource: {
            service_name: 'bennie',
            service_instance_id: 'production',
            telemetry_sdk_name: 'xreason-functions',
            telemetry_sdk_version: '7.0.2',
            host_hostname: 'codestrap.usw-3.palantirfoundry.com',
            host_architecture: 'prod',
        },
        operationName: 'submitRfpResponse',
        kind: 'Server',
        samplingDecision: 'RECORD_AND_SAMPLE',
        samplingRate: 1.0,
        attributes: { endpoint: '/api/v2/ontologies/ontology-c0c8a326-cd0a-4f69-a575-b0399c04b74d/queries/submitRfpResponse/execute' }
    })
    public async submitRfpResponse(query: string, userId: string, machineExecutionId: string): Promise<RfpResponseReceipt> {

        return {
            status: 200,
            message: `We've received your RFP response and are reviewing it with the customer. We'll get back to you shoortly.`,
            machineExecutionId: '123344jkl',
            reciept: {
                id: '',
                timestamp: Timestamp.now(),
            },
        }
    }
}